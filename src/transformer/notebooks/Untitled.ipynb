{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint \n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'nmt'\n",
    "en_vocab_file = os.path.join(output_dir, 'en_vocab')\n",
    "zh_vocab_file = os.path.join(output_dir, 'zh_vocab')\n",
    "ckpt_path = os.path.join(output_dir, 'ckpts')\n",
    "log_dir = os.path.join(output_dir, 'logs')\n",
    "download_dir = 'tensorflow-dataset/downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Split('train'): ['newscommentary_v14',\n",
      "                  'wikititles_v1',\n",
      "                  'uncorpus_v1',\n",
      "                  'casia2015',\n",
      "                  'casict2011',\n",
      "                  'casict2015',\n",
      "                  'datum2015',\n",
      "                  'datum2017',\n",
      "                  'neu2017'],\n",
      " Split('validation'): ['newstest2018']}\n"
     ]
    }
   ],
   "source": [
    "tmp_builder = tfds.builder('wmt19_translate/zh-en')\n",
    "pprint(tmp_builder.subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tfds.translate.wmt.WmtConfig(\n",
    "  version=tfds.core.Version('0.0.3', experiments={tfds.core.Experiment: False}),\n",
    "  language_pair=(\"zh\", \"en\"),\n",
    "  subsets={\n",
    "    tfds.Split.TRAIN: [\"newscommentary_v14\"]\n",
    "  }\n",
    ")\n",
    "builder = tfds.builder(\"wmt_translate\", config=config)\n",
    "builder.download_and_prepare(download_dir=download_dir)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, val_examples = builder.as_dataset(split=['train[:20%]', 'train[20%:30%]'], as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'The fear is real and visceral, and politicians ignore it at their peril.', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word \\xe2\\x80\\x9cliberal\\xe2\\x80\\x9d \\xe2\\x80\\x93 a champion of the cause of individual freedom.', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe4\\xba\\x8b\\xe5\\xae\\x9e\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe5\\xbe\\xb7\\xe5\\x9b\\xbd\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xb1\\x80\\xe5\\x8a\\xbf\\xe9\\x9c\\x80\\xe8\\xa6\\x81\\xe7\\x9a\\x84\\xe4\\xb8\\x8d\\xe8\\xbf\\x87\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe7\\xac\\xa6\\xe5\\x90\\x88\\xe7\\xbe\\x8e\\xe5\\x9b\\xbd\\xe6\\x89\\x80\\xe8\\xb0\\x93\\xe2\\x80\\x9c\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe2\\x80\\x9d\\xe5\\xae\\x9a\\xe4\\xb9\\x89\\xe7\\x9a\\x84\\xe7\\x9c\\x9f\\xe6\\xad\\xa3\\xe7\\x9a\\x84\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe5\\x85\\x9a\\xe6\\xb4\\xbe\\xef\\xbc\\x8c\\xe4\\xb9\\x9f\\xe5\\xb0\\xb1\\xe6\\x98\\xaf\\xe4\\xb8\\xaa\\xe4\\xba\\xba\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe4\\xba\\x8b\\xe4\\xb8\\x9a\\xe7\\x9a\\x84\\xe5\\x80\\xa1\\xe5\\xaf\\xbc\\xe8\\x80\\x85\\xe3\\x80\\x82', shape=(), dtype=string)\n",
      "----------\n",
      "tf.Tensor(b'Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe5\\xbf\\x85\\xe9\\xa1\\xbb\\xe4\\xbb\\x98\\xe5\\x87\\xba\\xe5\\xb7\\xa8\\xe5\\xa4\\xa7\\xe7\\x9a\\x84\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\x92\\x8c\\xe5\\x9f\\xba\\xe7\\xa1\\x80\\xe8\\xae\\xbe\\xe6\\x96\\xbd\\xe6\\x8a\\x95\\xe8\\xb5\\x84\\xe6\\x89\\x8d\\xe8\\x83\\xbd\\xe5\\xae\\x8c\\xe6\\x88\\x90\\xe5\\x90\\x91\\xe5\\x8f\\xaf\\xe5\\x86\\x8d\\xe7\\x94\\x9f\\xe8\\x83\\xbd\\xe6\\xba\\x90\\xe7\\x9a\\x84\\xe8\\xbf\\x87\\xe6\\xb8\\xa1\\xe3\\x80\\x82', shape=(), dtype=string)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for en, zh in train_examples.take(3):\n",
    "    print(en)\n",
    "    print(zh)\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fear is real and visceral, and politicians ignore it at their peril.\n",
      "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
      "----------\n",
      "In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word “liberal” – a champion of the cause of individual freedom.\n",
      "事实上，德国政治局势需要的不过是一个符合美国所谓“自由”定义的真正的自由党派，也就是个人自由事业的倡导者。\n",
      "----------\n",
      "Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.\n",
      "必须付出巨大的努力和基础设施投资才能完成向可再生能源的过渡。\n",
      "----------\n",
      "In this sense, it is critical to recognize the fundamental difference between “urban villages” and their rural counterparts.\n",
      "在这方面，关键在于认识到“城市村落”和农村村落之间的根本区别。\n",
      "----------\n",
      "A strong European voice, such as Nicolas Sarkozy’s during the French presidency of the EU, may make a difference, but only for six months, and at the cost of reinforcing other European countries’ nationalist feelings in reaction to the expression of “Gallic pride.”\n",
      "法国担任轮值主席国期间尼古拉·萨科奇统一的欧洲声音可能让人耳目一新，但这种声音却只持续了短短六个月，而且付出了让其他欧洲国家在面对“高卢人的骄傲”时民族主义情感进一步被激发的代价。\n",
      "----------\n",
      "Most of Japan’s bondholders are nationals (if not the central bank) and have an interest in political stability.\n",
      "日本债券持有人大多为本国国民（甚至中央银行 ） ， 政治稳定符合他们的利益。\n",
      "----------\n",
      "Paul Romer, one of the originators of new growth theory, has accused some leading names, including the Nobel laureate Robert Lucas, of what he calls “mathiness” – using math to obfuscate rather than clarify.\n",
      "新增长理论创始人之一的保罗·罗默（Paul Romer）也批评一些著名经济学家，包括诺贝尔奖获得者罗伯特·卢卡斯（Robert Lucas）在内，说他们“数学性 ” （ 罗默的用语）太重，结果是让问题变得更加模糊而不是更加清晰。\n",
      "----------\n",
      "It is, in fact, a capsule depiction of the United States Federal Reserve and the European Central Bank.\n",
      "事实上，这就是对美联储和欧洲央行的简略描述。\n",
      "----------\n",
      "Given these variables, the degree to which migration is affected by asylum-seekers will not be easy to predict or control.\n",
      "考虑到这些变量，移民受寻求庇护者的影响程度很难预测或控制。\n",
      "----------\n",
      "WASHINGTON, DC – In the 2016 American presidential election, Hillary Clinton and Donald Trump agreed that the US economy is suffering from dilapidated infrastructure, and both called for greater investment in renovating and upgrading the country’s public capital stock.\n",
      "华盛顿—在2016年美国总统选举中，希拉里·克林顿和唐纳德·特朗普都认为美国经济饱受基础设施陈旧的拖累，两人都要求加大投资用于修缮和升级美国公共资本存量。\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "sample_examples = []\n",
    "num_samples = 10\n",
    "\n",
    "for en_t, zh_t in train_examples.take(num_samples):\n",
    "    en = en_t.numpy().decode('utf-8')\n",
    "    zh = zh_t.numpy().decode('utf-8')\n",
    "    \n",
    "    print(en)\n",
    "    print(zh)\n",
    "    print('-' * 10)\n",
    "    \n",
    "    sample_examples.append((en, zh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load exists dict\n",
      "字典大小：8113\n",
      "前 10 個 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'is_', 'that_']\n",
      "\n",
      "CPU times: user 23.6 ms, sys: 1.57 ms, total: 25.2 ms\n",
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    subword_encoder_en = tfds.features.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
    "    print('Load exists dict')\n",
    "except:\n",
    "    print('There is no dict.  Build from the start.')\n",
    "    subword_encoder_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "        (en.numpy() for en, _ in train_examples),\n",
    "        target_vocab_size=2**13\n",
    "    )\n",
    "    \n",
    "    subword_encoder_en.save_to_file(en_vocab_file)\n",
    "\n",
    "print(f\"字典大小：{subword_encoder_en.vocab_size}\")\n",
    "print(f\"前 10 個 subwords：{subword_encoder_en.subwords[:10]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3461, 7889, 9, 3502, 4379, 1134, 7903]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_string = 'Taiwan is beautiful.'\n",
    "indices = subword_encoder_en.encode(sample_string)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index     Subword\n",
      "---------------\n",
      " 3461     Taiwan\n",
      " 7889      \n",
      "    9     is \n",
      " 3502     bea\n",
      " 4379     uti\n",
      " 1134     ful\n",
      " 7903     .\n"
     ]
    }
   ],
   "source": [
    "print('{0:10}{1:6}'.format('Index', 'Subword'))\n",
    "print('-' * 15)\n",
    "\n",
    "for idx in indices:\n",
    "    subword = subword_encoder_en.decode([idx])\n",
    "    print('{0:5}{1:6}'.format(idx, ' ' * 5 + subword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load exist dict\n",
      "字典大小：4205\n",
      "前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']\n",
      "\n",
      "CPU times: user 11.9 ms, sys: 3.8 ms, total: 15.7 ms\n",
      "Wall time: 20.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    subword_encoder_zh = tfds.features.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
    "    print('load exist dict')\n",
    "except:\n",
    "    print('There is no dict.  Build from start.')\n",
    "    subword_encoder_zh = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "        (zh.numpy() for _, zh in train_examples),\n",
    "        target_vocab_size=2**13,\n",
    "        max_subword_length=1\n",
    "    )\n",
    "    \n",
    "    subword_encoder_zh.save_to_file(zh_vocab_file)\n",
    "    \n",
    "print(f\"字典大小：{subword_encoder_zh.vocab_size}\")\n",
    "print(f\"前 10 個 subwords：{subword_encoder_zh.subwords[:10]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(en_t, zh_t):\n",
    "    en_indices = [subword_encoder_en.vocab_size] + subword_encoder_en.encode(en_t.numpy()) + [subword_encoder_en.vocab_size + 1]\n",
    "    zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(zh_t.numpy()) + [subword_encoder_zh.vocab_size + 1]\n",
    "    return en_indices, zh_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文 BOS 的 index 8113\n",
      "英文 BOS 的 index 8114\n",
      "中文 BOS 的 index 4205\n",
      "中文 BOS 的 index 4206\n",
      "\n",
      "輸入為 2 個 Tensors：\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'The fear is real and visceral, and politicians ignore it at their peril.'>,\n",
      " <tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82'>)\n",
      "---------------\n",
      "輸出為 2 個索引序列：\n",
      "([8113,\n",
      "  16,\n",
      "  1284,\n",
      "  9,\n",
      "  243,\n",
      "  5,\n",
      "  1275,\n",
      "  1756,\n",
      "  156,\n",
      "  1,\n",
      "  5,\n",
      "  1016,\n",
      "  5566,\n",
      "  21,\n",
      "  38,\n",
      "  33,\n",
      "  2982,\n",
      "  7965,\n",
      "  7903,\n",
      "  8114],\n",
      " [4205,\n",
      "  10,\n",
      "  151,\n",
      "  574,\n",
      "  1298,\n",
      "  6,\n",
      "  374,\n",
      "  55,\n",
      "  29,\n",
      "  193,\n",
      "  5,\n",
      "  1,\n",
      "  3,\n",
      "  3981,\n",
      "  931,\n",
      "  431,\n",
      "  125,\n",
      "  1,\n",
      "  17,\n",
      "  124,\n",
      "  33,\n",
      "  20,\n",
      "  97,\n",
      "  1089,\n",
      "  1247,\n",
      "  861,\n",
      "  3,\n",
      "  4206])\n"
     ]
    }
   ],
   "source": [
    "en_t, zh_t = next(iter(train_examples))\n",
    "en_indices, zh_indices = encode(en_t, zh_t)\n",
    "\n",
    "print('英文 BOS 的 index', subword_encoder_en.vocab_size)\n",
    "print('英文 BOS 的 index', subword_encoder_en.vocab_size + 1)\n",
    "print('中文 BOS 的 index', subword_encoder_zh.vocab_size)\n",
    "print('中文 BOS 的 index', subword_encoder_zh.vocab_size + 1)\n",
    "\n",
    "print('\\n輸入為 2 個 Tensors：')\n",
    "pprint((en_t, zh_t))\n",
    "print('-' * 15)\n",
    "print('輸出為 2 個索引序列：')\n",
    "pprint((en_indices, zh_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[8113   16 1284    9  243    5 1275 1756  156    1    5 1016 5566   21\n",
      "   38   33 2982 7965 7903 8114], shape=(20,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[4205   10  151  574 1298    6  374   55   29  193    5    1    3 3981\n",
      "  931  431  125    1   17  124   33   20   97 1089 1247  861    3 4206], shape=(28,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def tf_encode(en_t, zh_t):\n",
    "    return tf.py_function(encode, [en_t, zh_t], [tf.int64, tf.int64])\n",
    "\n",
    "\n",
    "tmp_dataset = train_examples.map(tf_encode)\n",
    "en_indices, zh_indices = next(iter(tmp_dataset))\n",
    "print(en_indices)\n",
    "print(zh_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "\n",
    "def filter_max_length(en, zh, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(en) <= max_length,\n",
    "                         tf.size(zh) <= max_length)\n",
    "\n",
    "\n",
    "tmp_dataset = tmp_dataset.filter(filter_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文索引序列的 batch\n",
      "tf.Tensor(\n",
      "[[8113   16 1284 ...    0    0    0]\n",
      " [8113 1894 1302 ...    0    0    0]\n",
      " [8113   44   40 ...    0    0    0]\n",
      " ...\n",
      " [8113  122  506 ...    0    0    0]\n",
      " [8113   16  215 ...    0    0    0]\n",
      " [8113 7443 7889 ...    0    0    0]], shape=(64, 39), dtype=int64)\n",
      "--------------------\n",
      "中文索引序列的 batch\n",
      "tf.Tensor(\n",
      "[[4205   10  151 ...    0    0    0]\n",
      " [4205  206  275 ...    0    0    0]\n",
      " [4205    5   10 ...    0    0    0]\n",
      " ...\n",
      " [4205   34    6 ...    0    0    0]\n",
      " [4205  317  256 ...    0    0    0]\n",
      " [4205  167  326 ...    0    0    0]], shape=(64, 40), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "# 將 batch 裡的所有序列都 pad 到同樣長度\n",
    "tmp_dataset = tmp_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "en_batch, zh_batch = next(iter(tmp_dataset))\n",
    "print(\"英文索引序列的 batch\")\n",
    "print(en_batch)\n",
    "print('-' * 20)\n",
    "print(\"中文索引序列的 batch\")\n",
    "print(zh_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 15000\n",
    "\n",
    "# 訓練集\n",
    "train_dataset = (train_examples  # 輸出：(英文句子, 中文句子)\n",
    "                 .map(tf_encode) # 輸出：(英文索引序列, 中文索引序列)\n",
    "                 .filter(filter_max_length) # 同上，且序列長度都不超過 40\n",
    "                 .cache() # 加快讀取數據\n",
    "                 .shuffle(BUFFER_SIZE) # 將例子洗牌確保隨機性\n",
    "                 .padded_batch(BATCH_SIZE, # 將 batch 裡的序列都 pad 到一樣長度\n",
    "                               padded_shapes=([-1], [-1]))\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
    "# 驗證集\n",
    "val_dataset = (val_examples\n",
    "               .map(tf_encode)\n",
    "               .filter(filter_max_length)\n",
    "               .padded_batch(BATCH_SIZE, \n",
    "                             padded_shapes=([-1], [-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文索引序列的 batch\n",
      "tf.Tensor(\n",
      "[[8113 7064 1975 ...    0    0    0]\n",
      " [8113 4154 5813 ...    0    0    0]\n",
      " [8113 5261 5814 ...    0    0    0]\n",
      " ...\n",
      " [8113   44   40 ...    0    0    0]\n",
      " [8113   16 5037 ...    0    0    0]\n",
      " [8113 1392    1 ...    0    0    0]], shape=(128, 39), dtype=int64)\n",
      "--------------------\n",
      "中文索引序列的 batch\n",
      "tf.Tensor(\n",
      "[[4205  677  198 ...    0    0    0]\n",
      " [4205  327  363 ...    0    0    0]\n",
      " [4205  146  450 ... 4206    0    0]\n",
      " ...\n",
      " [4205  146   10 ...    0    0    0]\n",
      " [4205   73   76 ...    0    0    0]\n",
      " [4205   72  107 ...    0    0    0]], shape=(128, 40), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "en_batch, zh_batch = next(iter(train_dataset))\n",
    "print(\"英文索引序列的 batch\")\n",
    "print(en_batch)\n",
    "print('-' * 20)\n",
    "print(\"中文索引序列的 batch\")\n",
    "print(zh_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It is important.', '这很重要。'),\n",
      " ('The numbers speak for themselves.', '数字证明了一切。')]\n"
     ]
    }
   ],
   "source": [
    "demo_examples = [\n",
    "    (\"It is important.\", \"这很重要。\"),\n",
    "    (\"The numbers speak for themselves.\", \"数字证明了一切。\"),\n",
    "]\n",
    "pprint(demo_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tf.Tensor(\n",
      "[[8113  103    9 1066 7903 8114    0    0]\n",
      " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
      "\n",
      "tar: tf.Tensor(\n",
      "[[4205   10  241   86   27    3 4206    0    0    0]\n",
      " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
    "    [en for en, _ in demo_examples], [zh for _, zh in demo_examples]\n",
    "))\n",
    "\n",
    "# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）\n",
    "# 並添加 padding token: <pad> 來確保 batch 裡的句子有一樣長度\n",
    "demo_dataset = demo_examples.map(tf_encode)\\\n",
    "  .padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
    "\n",
    "# 取出這個 demo dataset 裡唯一一個 batch\n",
    "inp, tar = next(iter(demo_dataset))\n",
    "print('inp:', inp)\n",
    "print('' * 10)\n",
    "print('tar:', tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "\n",
    "inp_mask = create_padding_mask(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tf.Tensor(\n",
      "[[8113  103    9 1066 7903 8114    0    0]\n",
      " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
      "--------------------------------------------------\n",
      "inp_mask tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('inp:', inp)\n",
    "print('-'*50)\n",
    "print('inp_mask', tf.squeeze(inp_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
       " array([[[-0.02297657, -0.04122313,  0.03381893, -0.01937288],\n",
       "         [-0.00796111,  0.03261266, -0.00197904, -0.00650675],\n",
       "         [ 0.03392147,  0.01473037, -0.01506079, -0.00136057],\n",
       "         [-0.00279899,  0.00668357, -0.01596413, -0.03195436],\n",
       "         [ 0.04876539, -0.01745915, -0.00553452,  0.03104443],\n",
       "         [ 0.02287232,  0.00264494, -0.00776212,  0.00823762],\n",
       "         [ 0.02976597,  0.00305575, -0.02176636, -0.04857057],\n",
       "         [ 0.02976597,  0.00305575, -0.02176636, -0.04857057]],\n",
       " \n",
       "        [[-0.02297657, -0.04122313,  0.03381893, -0.01937288],\n",
       "         [ 0.04378113, -0.02505095, -0.00220025,  0.01047223],\n",
       "         [ 0.02366493,  0.0475367 , -0.03152323, -0.02946496],\n",
       "         [ 0.03044384,  0.02730397, -0.02224587, -0.02248793],\n",
       "         [ 0.04138756, -0.02679635,  0.02611503, -0.04867743],\n",
       "         [-0.04007994,  0.04466505, -0.01300593,  0.01717355],\n",
       "         [ 0.04876539, -0.01745915, -0.00553452,  0.03104443],\n",
       "         [ 0.02287232,  0.00264494, -0.00776212,  0.00823762]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
       " array([[[ 3.5666537e-02,  5.5825487e-03,  5.4331906e-03,  4.0096808e-02],\n",
       "         [ 7.2124116e-03, -4.1118335e-02, -2.7754916e-02, -4.1599952e-02],\n",
       "         [-1.7930616e-02, -1.8189169e-02, -1.3243929e-03, -4.7433127e-02],\n",
       "         [-1.3495907e-03,  1.7305706e-02, -1.5348159e-02, -4.1189052e-02],\n",
       "         [-1.5888382e-02, -4.5061111e-05, -4.7153607e-03,  2.2980023e-02],\n",
       "         [ 4.8545565e-02, -4.0312864e-02,  4.5347214e-04,  4.1490231e-02],\n",
       "         [-4.0585827e-02,  2.0542037e-02,  2.9793326e-02, -1.9847764e-02],\n",
       "         [ 4.1308645e-02, -4.2330813e-02,  3.7144307e-02,  6.7838058e-03],\n",
       "         [ 4.1308645e-02, -4.2330813e-02,  3.7144307e-02,  6.7838058e-03],\n",
       "         [ 4.1308645e-02, -4.2330813e-02,  3.7144307e-02,  6.7838058e-03]],\n",
       " \n",
       "        [[ 3.5666537e-02,  5.5825487e-03,  5.4331906e-03,  4.0096808e-02],\n",
       "         [-3.7920427e-02,  3.2582048e-02,  3.9499886e-03, -2.5687337e-02],\n",
       "         [-3.1952970e-03, -4.6193227e-03, -3.7512720e-02,  2.8303992e-02],\n",
       "         [ 3.6210943e-02, -6.2573664e-03,  1.4258470e-02, -3.1804100e-02],\n",
       "         [ 1.4585648e-02, -1.7319262e-02,  3.2460537e-02,  2.3770537e-02],\n",
       "         [ 2.6244011e-02, -1.9685602e-02, -1.6457953e-02,  1.2792002e-02],\n",
       "         [-1.8107474e-02,  3.7484203e-02, -3.1281710e-02,  3.7694279e-02],\n",
       "         [ 2.7637366e-02,  3.9375473e-02,  6.1774962e-03,  2.6192974e-02],\n",
       "         [ 4.8545565e-02, -4.0312864e-02,  4.5347214e-04,  4.1490231e-02],\n",
       "         [-4.0585827e-02,  2.0542037e-02,  2.9793326e-02, -1.9847764e-02]]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# + 2 是因為我們額外加了 <start> 以及 <end> tokens\n",
    "vocab_size_en = subword_encoder_en.vocab_size + 2\n",
    "vocab_size_zh = subword_encoder_zh.vocab_size + 2\n",
    "\n",
    "# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間\n",
    "d_model = 4\n",
    "embedding_layer_en = tf.keras.layers.Embedding(vocab_size_en, d_model)\n",
    "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh, d_model)\n",
    "\n",
    "emb_inp = embedding_layer_en(inp)\n",
    "emb_tar = embedding_layer_zh(tar)\n",
    "emb_inp, emb_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(9527)\n",
    "q = emb_inp\n",
    "k = emb_inp\n",
    "\n",
    "v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_inp.shape), 0.5), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    \n",
    "    q, k, v msut hvae matching leading dimensions.\n",
    "    k, v must have matching penulatimate dimension, i.e: seq_len_k = seq_len_v.\n",
    "    The mask has different shape depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "    \n",
    "    Args:\n",
    "        q: qeury shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth)\n",
    "        mask: Float tensor with shape broadcastable\n",
    "                to (..., seq_len_q, seq_len_k). Defaults to None\n",
    "    \n",
    "    Returns:\n",
    "        output, attention_weights\n",
    "    \"\"\"\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    \n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attention_weights = scaled_dot_product_attention(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tf.Tensor(\n",
      "[[[0.37521768 0.37489307 0.37494543 0.49979818]\n",
      "  [0.3748902  0.37507972 0.37497297 0.5000956 ]\n",
      "  [0.37486172 0.37503427 0.37506902 0.50009096]\n",
      "  [0.3749019  0.37503254 0.3750249  0.5000169 ]\n",
      "  [0.3750128  0.37494376 0.37508774 0.50001013]\n",
      "  [0.37494963 0.3750031  0.37504426 0.50004125]\n",
      "  [0.37482387 0.37502173 0.3750947  0.50002766]\n",
      "  [0.37482387 0.37502173 0.3750947  0.50002766]]\n",
      "\n",
      " [[0.6249323  0.2500742  0.6250535  0.37533674]\n",
      "  [0.6247665  0.24986461 0.62485605 0.37480456]\n",
      "  [0.6251128  0.24998832 0.6248617  0.3747517 ]\n",
      "  [0.62501323 0.24995726 0.624849   0.37477267]\n",
      "  [0.6247715  0.24996923 0.6247686  0.37503192]\n",
      "  [0.6252786  0.25009668 0.6251763  0.3750379 ]\n",
      "  [0.62476134 0.24983317 0.6248728  0.374716  ]\n",
      "  [0.62493014 0.24993305 0.62492955 0.37484244]]], shape=(2, 8, 4), dtype=float32)\n",
      "--------------------------------------------------\n",
      "attention tf.Tensor(\n",
      "[[[0.12525634 0.12495305 0.12490512 0.1250137  0.12494761 0.1249559\n",
      "   0.12498412 0.12498412]\n",
      "  [0.12493142 0.12507364 0.12501585 0.12503028 0.12492853 0.12499192\n",
      "   0.12501416 0.12501416]\n",
      "  [0.12484013 0.12497244 0.12505665 0.12497484 0.12504676 0.12501441\n",
      "   0.12504742 0.12504742]\n",
      "  [0.12495819 0.12499643 0.12498441 0.12504949 0.12489419 0.12495484\n",
      "   0.12508126 0.12508126]\n",
      "  [0.12490215 0.12490468 0.12506634 0.12490418 0.12520644 0.12506196\n",
      "   0.12497712 0.12497712]\n",
      "  [0.12491456 0.12497219 0.12503812 0.12496898 0.12506609 0.12502171\n",
      "   0.12500918 0.12500918]\n",
      "  [0.12487762 0.12492926 0.12500592 0.12503017 0.12491608 0.12494399\n",
      "   0.12514848 0.12514848]\n",
      "  [0.12487762 0.12492926 0.12500592 0.12503017 0.12491608 0.12494399\n",
      "   0.12514848 0.12514848]]\n",
      "\n",
      " [[0.1252625  0.12501243 0.12484077 0.12489426 0.12515192 0.1249223\n",
      "   0.12495375 0.12496204]\n",
      "  [0.12493996 0.12512185 0.12493101 0.1249845  0.12507538 0.12478922\n",
      "   0.12513754 0.12502052]\n",
      "  [0.12476337 0.12492595 0.1252434  0.12516205 0.12497035 0.12501797\n",
      "   0.12492457 0.12499237]\n",
      "  [0.12481539 0.12497801 0.1251606  0.12511623 0.12501423 0.12494303\n",
      "   0.12497617 0.12499636]\n",
      "  [0.12506267 0.12505868 0.12495871 0.12500404 0.12528189 0.12468734\n",
      "   0.12499081 0.12495593]\n",
      "  [0.12494122 0.12488049 0.12511449 0.12504092 0.12479523 0.12530147\n",
      "   0.12491397 0.12501225]\n",
      "  [0.12488284 0.12513904 0.12493113 0.12498417 0.12500902 0.12482416\n",
      "   0.12518708 0.12504262]\n",
      "  [0.12490939 0.12504031 0.12501721 0.12502265 0.1249924  0.12494065\n",
      "   0.1250609  0.12501654]]], shape=(2, 8, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('output:', output)\n",
    "print('-' * 50)\n",
    "print('attention', attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.16700138 0.16659701 0.1665331  0.16667785 0.16658977 0.16660081\n",
      "   0.         0.        ]\n",
      "  [0.16658151 0.16677116 0.1666941  0.16671334 0.16657767 0.16666219\n",
      "   0.         0.        ]\n",
      "  [0.16647454 0.16665098 0.16676328 0.16665417 0.16675009 0.16670693\n",
      "   0.         0.        ]\n",
      "  [0.16664703 0.16669802 0.16668199 0.16676877 0.16656166 0.16664258\n",
      "   0.         0.        ]\n",
      "  [0.16652603 0.16652942 0.16674495 0.16652875 0.16693173 0.16673909\n",
      "   0.         0.        ]\n",
      "  [0.16655684 0.16663368 0.16672157 0.16662939 0.16675887 0.16669971\n",
      "   0.         0.        ]\n",
      "  [0.16656946 0.16663833 0.16674058 0.16677293 0.16662075 0.16665798\n",
      "   0.         0.        ]\n",
      "  [0.16656946 0.16663833 0.16674058 0.16677293 0.16662075 0.16665798\n",
      "   0.         0.        ]]\n",
      "\n",
      " [[0.1252625  0.12501243 0.12484077 0.12489426 0.12515192 0.1249223\n",
      "   0.12495375 0.12496204]\n",
      "  [0.12493996 0.12512185 0.12493101 0.1249845  0.12507538 0.12478922\n",
      "   0.12513754 0.12502052]\n",
      "  [0.12476337 0.12492595 0.1252434  0.12516205 0.12497035 0.12501797\n",
      "   0.12492457 0.12499237]\n",
      "  [0.12481539 0.12497801 0.1251606  0.12511623 0.12501423 0.12494303\n",
      "   0.12497617 0.12499636]\n",
      "  [0.12506267 0.12505868 0.12495871 0.12500404 0.12528189 0.12468734\n",
      "   0.12499081 0.12495593]\n",
      "  [0.12494122 0.12488049 0.12511449 0.12504092 0.12479523 0.12530147\n",
      "   0.12491397 0.12501225]\n",
      "  [0.12488284 0.12513904 0.12493113 0.12498417 0.12500902 0.12482416\n",
      "   0.12518708 0.12504262]\n",
      "  [0.12490939 0.12504031 0.12501721 0.12502265 0.1249924  0.12494065\n",
      "   0.1250609  0.12501654]]], shape=(2, 8, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mask = tf.squeeze(inp_mask, axis=1)\n",
    "_, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_tar: tf.Tensor(\n",
      "[[[ 3.5666537e-02  5.5825487e-03  5.4331906e-03  4.0096808e-02]\n",
      "  [ 7.2124116e-03 -4.1118335e-02 -2.7754916e-02 -4.1599952e-02]\n",
      "  [-1.7930616e-02 -1.8189169e-02 -1.3243929e-03 -4.7433127e-02]\n",
      "  [-1.3495907e-03  1.7305706e-02 -1.5348159e-02 -4.1189052e-02]\n",
      "  [-1.5888382e-02 -4.5061111e-05 -4.7153607e-03  2.2980023e-02]\n",
      "  [ 4.8545565e-02 -4.0312864e-02  4.5347214e-04  4.1490231e-02]\n",
      "  [-4.0585827e-02  2.0542037e-02  2.9793326e-02 -1.9847764e-02]\n",
      "  [ 4.1308645e-02 -4.2330813e-02  3.7144307e-02  6.7838058e-03]\n",
      "  [ 4.1308645e-02 -4.2330813e-02  3.7144307e-02  6.7838058e-03]\n",
      "  [ 4.1308645e-02 -4.2330813e-02  3.7144307e-02  6.7838058e-03]]\n",
      "\n",
      " [[ 3.5666537e-02  5.5825487e-03  5.4331906e-03  4.0096808e-02]\n",
      "  [-3.7920427e-02  3.2582048e-02  3.9499886e-03 -2.5687337e-02]\n",
      "  [-3.1952970e-03 -4.6193227e-03 -3.7512720e-02  2.8303992e-02]\n",
      "  [ 3.6210943e-02 -6.2573664e-03  1.4258470e-02 -3.1804100e-02]\n",
      "  [ 1.4585648e-02 -1.7319262e-02  3.2460537e-02  2.3770537e-02]\n",
      "  [ 2.6244011e-02 -1.9685602e-02 -1.6457953e-02  1.2792002e-02]\n",
      "  [-1.8107474e-02  3.7484203e-02 -3.1281710e-02  3.7694279e-02]\n",
      "  [ 2.7637366e-02  3.9375473e-02  6.1774962e-03  2.6192974e-02]\n",
      "  [ 4.8545565e-02 -4.0312864e-02  4.5347214e-04  4.1490231e-02]\n",
      "  [-4.0585827e-02  2.0542037e-02  2.9793326e-02 -1.9847764e-02]]], shape=(2, 10, 4), dtype=float32)\n",
      "--------------------------------------------------\n",
      "look_ahead_mask tf.Tensor(\n",
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "seq_len = emb_tar.shape[1]\n",
    "look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "print('emb_tar:', emb_tar)\n",
    "print('-' * 50)\n",
    "print('look_ahead_mask', look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights: tf.Tensor(\n",
      "[[1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.49985787 0.5001421  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.3330306  0.33368912 0.33328027 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.24978316 0.2501955  0.24991067 0.25011066 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.20003313 0.19999945 0.20008808 0.19986297 0.20001645 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.16684994 0.16623451 0.16668451 0.16664355 0.16678612 0.16680142\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.14275907 0.1431023  0.14278208 0.1428608  0.14286722 0.14274146\n",
      "  0.14288701 0.         0.         0.        ]\n",
      " [0.12510368 0.12481104 0.12492563 0.12512645 0.12516575 0.1250838\n",
      "  0.12479433 0.12498935 0.         0.        ]\n",
      " [0.11117881 0.11091873 0.11102057 0.11119903 0.11123395 0.11116114\n",
      "  0.11090388 0.1110772  0.1113067  0.        ]\n",
      " [0.10007127 0.09983717 0.09992883 0.10008947 0.1001209  0.10005535\n",
      "  0.09982381 0.0999798  0.10018638 0.09990703]], shape=(10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tmp_q, tmp_k = emb_tar\n",
    "tmp_v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_tar.shape), 0.5), tf.float32)\n",
    "\n",
    "_, attention_weights = scaled_dot_product_attention(tmp_q, tmp_k ,tmp_v, look_ahead_mask)\n",
    "\n",
    "print('attention_weights:', attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tf.Tensor(\n",
      "[[[-0.02297657 -0.04122313  0.03381893 -0.01937288]\n",
      "  [-0.00796111  0.03261266 -0.00197904 -0.00650675]\n",
      "  [ 0.03392147  0.01473037 -0.01506079 -0.00136057]\n",
      "  [-0.00279899  0.00668357 -0.01596413 -0.03195436]\n",
      "  [ 0.04876539 -0.01745915 -0.00553452  0.03104443]\n",
      "  [ 0.02287232  0.00264494 -0.00776212  0.00823762]\n",
      "  [ 0.02976597  0.00305575 -0.02176636 -0.04857057]\n",
      "  [ 0.02976597  0.00305575 -0.02176636 -0.04857057]]\n",
      "\n",
      " [[-0.02297657 -0.04122313  0.03381893 -0.01937288]\n",
      "  [ 0.04378113 -0.02505095 -0.00220025  0.01047223]\n",
      "  [ 0.02366493  0.0475367  -0.03152323 -0.02946496]\n",
      "  [ 0.03044384  0.02730397 -0.02224587 -0.02248793]\n",
      "  [ 0.04138756 -0.02679635  0.02611503 -0.04867743]\n",
      "  [-0.04007994  0.04466505 -0.01300593  0.01717355]\n",
      "  [ 0.04876539 -0.01745915 -0.00553452  0.03104443]\n",
      "  [ 0.02287232  0.00264494 -0.00776212  0.00823762]]], shape=(2, 8, 4), dtype=float32)\n",
      "output: tf.Tensor(\n",
      "[[[[-0.02297657 -0.04122313]\n",
      "   [-0.00796111  0.03261266]\n",
      "   [ 0.03392147  0.01473037]\n",
      "   [-0.00279899  0.00668357]\n",
      "   [ 0.04876539 -0.01745915]\n",
      "   [ 0.02287232  0.00264494]\n",
      "   [ 0.02976597  0.00305575]\n",
      "   [ 0.02976597  0.00305575]]\n",
      "\n",
      "  [[ 0.03381893 -0.01937288]\n",
      "   [-0.00197904 -0.00650675]\n",
      "   [-0.01506079 -0.00136057]\n",
      "   [-0.01596413 -0.03195436]\n",
      "   [-0.00553452  0.03104443]\n",
      "   [-0.00776212  0.00823762]\n",
      "   [-0.02176636 -0.04857057]\n",
      "   [-0.02176636 -0.04857057]]]\n",
      "\n",
      "\n",
      " [[[-0.02297657 -0.04122313]\n",
      "   [ 0.04378113 -0.02505095]\n",
      "   [ 0.02366493  0.0475367 ]\n",
      "   [ 0.03044384  0.02730397]\n",
      "   [ 0.04138756 -0.02679635]\n",
      "   [-0.04007994  0.04466505]\n",
      "   [ 0.04876539 -0.01745915]\n",
      "   [ 0.02287232  0.00264494]]\n",
      "\n",
      "  [[ 0.03381893 -0.01937288]\n",
      "   [-0.00220025  0.01047223]\n",
      "   [-0.03152323 -0.02946496]\n",
      "   [-0.02224587 -0.02248793]\n",
      "   [ 0.02611503 -0.04867743]\n",
      "   [-0.01300593  0.01717355]\n",
      "   [-0.00553452  0.03104443]\n",
      "   [-0.00776212  0.00823762]]]], shape=(2, 2, 8, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def split_heads(x, d_model, num_heads):\n",
    "    # x.shape: (batch_size, seq_len, d_model)\n",
    "    batch_size = tf.shape(x)[0]\n",
    "  \n",
    "    # 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度\n",
    "    assert d_model % num_heads == 0\n",
    "    depth = d_model // num_heads  # 這是分成多頭以後每個向量的維度 \n",
    "  \n",
    "    # 將最後一個 d_model 維度分成 num_heads 個 depth 維度。\n",
    "    # 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維\n",
    "    # (batch_size, seq_len, num_heads, depth)\n",
    "    reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
    "  \n",
    "    # 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量\n",
    "    # (batch_size, num_heads, seq_len, depth)\n",
    "    output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
    "  \n",
    "    return output\n",
    "\n",
    "# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量\n",
    "d_model = 4\n",
    "# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣\n",
    "num_heads = 2\n",
    "x = emb_inp\n",
    "\n",
    "output = split_heads(x, d_model, num_heads)  \n",
    "print(\"x:\", x)\n",
    "print(\"output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model: 4\n",
      "num_heads: 2\n",
      "q.shape: (2, 8, 4)\n",
      "k.shape: (2, 8, 4)\n",
      "v.shape: (2, 8, 4)\n",
      "padding_mask.shape: (2, 1, 1, 8)\n",
      "output.shape: (2, 8, 4)\n",
      "attention_weights.shape: (2, 2, 8, 8)\n",
      "\n",
      "output: tf.Tensor(\n",
      "[[[ 0.01288779 -0.00919982 -0.00923284 -0.00198364]\n",
      "  [ 0.01287623 -0.00920211 -0.00924341 -0.00196247]\n",
      "  [ 0.01287655 -0.00920623 -0.00925122 -0.00195355]\n",
      "  [ 0.01287263 -0.00919964 -0.0092411  -0.0019619 ]\n",
      "  [ 0.01288756 -0.00921092 -0.00925501 -0.00195726]\n",
      "  [ 0.01288115 -0.00920624 -0.00924921 -0.00195916]\n",
      "  [ 0.01286814 -0.00920093 -0.00924509 -0.00195434]\n",
      "  [ 0.01286814 -0.00920093 -0.00924509 -0.00195434]]\n",
      "\n",
      " [[ 0.01634819 -0.00924758 -0.01036824 -0.00086632]\n",
      "  [ 0.01634617 -0.00925161 -0.01041402 -0.00078698]\n",
      "  [ 0.0163274  -0.00924201 -0.01042373 -0.00074827]\n",
      "  [ 0.01633203 -0.00924439 -0.01042066 -0.00075906]\n",
      "  [ 0.01634008 -0.00924724 -0.0103969  -0.00081006]\n",
      "  [ 0.01634056 -0.00924514 -0.01039747 -0.00080687]\n",
      "  [ 0.01634921 -0.00925385 -0.01042158 -0.00077777]\n",
      "  [ 0.01634275 -0.00924913 -0.0104124  -0.0007854 ]]], shape=(2, 8, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "assert d_model == emb_inp.shape[-1] == 4\n",
    "num_heads = 2\n",
    "\n",
    "print('d_model:', d_model)\n",
    "print('num_heads:', num_heads)\n",
    "\n",
    "mha = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "v = k = v = emb_inp\n",
    "padding_mask = create_padding_mask(inp)\n",
    "print('q.shape:', q.shape)\n",
    "print('k.shape:', k.shape)\n",
    "print('v.shape:', v.shape)\n",
    "print('padding_mask.shape:', padding_mask.shape)\n",
    "\n",
    "output, attention_weights = mha(v, k, q, mask)\n",
    "print('output.shape:', output.shape)\n",
    "print('attention_weights.shape:', attention_weights.shape)\n",
    "print('\\noutput:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, attn = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tf.Tensor(\n",
      "[[8113  103    9 1066 7903 8114    0    0]\n",
      " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
      "--------------------\n",
      "padding_mask: tf.Tensor(\n",
      "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
      "--------------------\n",
      "emb_inp: tf.Tensor(\n",
      "[[[-0.02297657 -0.04122313  0.03381893 -0.01937288]\n",
      "  [-0.00796111  0.03261266 -0.00197904 -0.00650675]\n",
      "  [ 0.03392147  0.01473037 -0.01506079 -0.00136057]\n",
      "  [-0.00279899  0.00668357 -0.01596413 -0.03195436]\n",
      "  [ 0.04876539 -0.01745915 -0.00553452  0.03104443]\n",
      "  [ 0.02287232  0.00264494 -0.00776212  0.00823762]\n",
      "  [ 0.02976597  0.00305575 -0.02176636 -0.04857057]\n",
      "  [ 0.02976597  0.00305575 -0.02176636 -0.04857057]]\n",
      "\n",
      " [[-0.02297657 -0.04122313  0.03381893 -0.01937288]\n",
      "  [ 0.04378113 -0.02505095 -0.00220025  0.01047223]\n",
      "  [ 0.02366493  0.0475367  -0.03152323 -0.02946496]\n",
      "  [ 0.03044384  0.02730397 -0.02224587 -0.02248793]\n",
      "  [ 0.04138756 -0.02679635  0.02611503 -0.04867743]\n",
      "  [-0.04007994  0.04466505 -0.01300593  0.01717355]\n",
      "  [ 0.04876539 -0.01745915 -0.00553452  0.03104443]\n",
      "  [ 0.02287232  0.00264494 -0.00776212  0.00823762]]], shape=(2, 8, 4), dtype=float32)\n",
      "--------------------\n",
      "enc_out: tf.Tensor(\n",
      "[[[-1.1575519  -0.2971137   1.5973238  -0.14265834]\n",
      "  [-0.9228337   1.5964692  -0.76853764  0.09490207]\n",
      "  [ 1.4062785   0.1653283  -1.4022739  -0.16933282]\n",
      "  [ 0.9020568   1.0853909  -1.1226453  -0.86480254]\n",
      "  [ 1.3579528  -0.4724527  -1.3204445   0.43494418]\n",
      "  [ 1.1798257  -0.01423969 -1.5647581   0.3991719 ]\n",
      "  [ 1.5312122   0.25004336 -0.83392626 -0.9473292 ]\n",
      "  [ 1.5312122   0.25004336 -0.83392626 -0.9473292 ]]\n",
      "\n",
      " [[-1.3147861  -0.23220295  1.4879279   0.05906117]\n",
      "  [ 1.5008122  -0.5169693  -1.1977295   0.2138865 ]\n",
      "  [ 1.1064814   0.7773912  -1.3873968  -0.4964758 ]\n",
      "  [ 1.3004909   0.50924504 -1.3586404  -0.4510954 ]\n",
      "  [ 1.1782947  -0.39302555  0.64390457 -1.4291736 ]\n",
      "  [-1.4261411   0.8151908  -0.44116765  1.052118  ]\n",
      "  [ 1.2346314  -0.4166528  -1.4008405   0.58286184]\n",
      "  [ 0.9247211   0.05963784 -1.6447526   0.6603937 ]]], shape=(2, 8, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 之後可以調的超參數。這邊為了 demo 設小一點\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "\n",
    "# 新建一個使用上述參數的 Encoder Layer\n",
    "enc_layer = EncoderLayer(d_model, num_heads, dff)\n",
    "padding_mask = create_padding_mask(inp)  # 建立一個當前輸入 batch 使用的 padding mask\n",
    "enc_out = enc_layer(emb_inp, training=False, mask=padding_mask)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "print(\"inp:\", inp)\n",
    "print(\"-\" * 20)\n",
    "print(\"padding_mask:\", padding_mask)\n",
    "print(\"-\" * 20)\n",
    "print(\"emb_inp:\", emb_inp)\n",
    "print(\"-\" * 20)\n",
    "print(\"enc_out:\", enc_out)\n",
    "assert emb_inp.shape == enc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, combined_mask, inp_padding_mask):\n",
    "        attn1, attn_weights_bolck1 = self.mha1(x, x, x, combined_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, inp_padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "        \n",
    "        return out3, attn_weights_bolck1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: tf.Tensor(\n",
      "[[4205   10  241   86   27    3 4206    0    0    0]\n",
      " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
      "tar_padding_mask: tf.Tensor(\n",
      "[[[[0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)\n",
      "look_ahead_mask: tf.Tensor(\n",
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
      "combined_mask: tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tar_padding_mask = create_padding_mask(tar)\n",
    "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
    "combine_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "print('tar:', tar)\n",
    "print('tar_padding_mask:', tar_padding_mask)\n",
    "print('look_ahead_mask:', look_ahead_mask)\n",
    "print('combined_mask:', combine_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_tar: tf.Tensor(\n",
      "[[[ 3.5666537e-02  5.5825487e-03  5.4331906e-03  4.0096808e-02]\n",
      "  [ 7.2124116e-03 -4.1118335e-02 -2.7754916e-02 -4.1599952e-02]\n",
      "  [-1.7930616e-02 -1.8189169e-02 -1.3243929e-03 -4.7433127e-02]\n",
      "  [-1.3495907e-03  1.7305706e-02 -1.5348159e-02 -4.1189052e-02]\n",
      "  [-1.5888382e-02 -4.5061111e-05 -4.7153607e-03  2.2980023e-02]\n",
      "  [ 4.8545565e-02 -4.0312864e-02  4.5347214e-04  4.1490231e-02]\n",
      "  [-4.0585827e-02  2.0542037e-02  2.9793326e-02 -1.9847764e-02]\n",
      "  [ 4.1308645e-02 -4.2330813e-02  3.7144307e-02  6.7838058e-03]\n",
      "  [ 4.1308645e-02 -4.2330813e-02  3.7144307e-02  6.7838058e-03]\n",
      "  [ 4.1308645e-02 -4.2330813e-02  3.7144307e-02  6.7838058e-03]]\n",
      "\n",
      " [[ 3.5666537e-02  5.5825487e-03  5.4331906e-03  4.0096808e-02]\n",
      "  [-3.7920427e-02  3.2582048e-02  3.9499886e-03 -2.5687337e-02]\n",
      "  [-3.1952970e-03 -4.6193227e-03 -3.7512720e-02  2.8303992e-02]\n",
      "  [ 3.6210943e-02 -6.2573664e-03  1.4258470e-02 -3.1804100e-02]\n",
      "  [ 1.4585648e-02 -1.7319262e-02  3.2460537e-02  2.3770537e-02]\n",
      "  [ 2.6244011e-02 -1.9685602e-02 -1.6457953e-02  1.2792002e-02]\n",
      "  [-1.8107474e-02  3.7484203e-02 -3.1281710e-02  3.7694279e-02]\n",
      "  [ 2.7637366e-02  3.9375473e-02  6.1774962e-03  2.6192974e-02]\n",
      "  [ 4.8545565e-02 -4.0312864e-02  4.5347214e-04  4.1490231e-02]\n",
      "  [-4.0585827e-02  2.0542037e-02  2.9793326e-02 -1.9847764e-02]]], shape=(2, 10, 4), dtype=float32)\n",
      "--------------------\n",
      "enc_out: tf.Tensor(\n",
      "[[[-1.1575519  -0.2971137   1.5973238  -0.14265834]\n",
      "  [-0.9228337   1.5964692  -0.76853764  0.09490207]\n",
      "  [ 1.4062785   0.1653283  -1.4022739  -0.16933282]\n",
      "  [ 0.9020568   1.0853909  -1.1226453  -0.86480254]\n",
      "  [ 1.3579528  -0.4724527  -1.3204445   0.43494418]\n",
      "  [ 1.1798257  -0.01423969 -1.5647581   0.3991719 ]\n",
      "  [ 1.5312122   0.25004336 -0.83392626 -0.9473292 ]\n",
      "  [ 1.5312122   0.25004336 -0.83392626 -0.9473292 ]]\n",
      "\n",
      " [[-1.3147861  -0.23220295  1.4879279   0.05906117]\n",
      "  [ 1.5008122  -0.5169693  -1.1977295   0.2138865 ]\n",
      "  [ 1.1064814   0.7773912  -1.3873968  -0.4964758 ]\n",
      "  [ 1.3004909   0.50924504 -1.3586404  -0.4510954 ]\n",
      "  [ 1.1782947  -0.39302555  0.64390457 -1.4291736 ]\n",
      "  [-1.4261411   0.8151908  -0.44116765  1.052118  ]\n",
      "  [ 1.2346314  -0.4166528  -1.4008405   0.58286184]\n",
      "  [ 0.9247211   0.05963784 -1.6447526   0.6603937 ]]], shape=(2, 8, 4), dtype=float32)\n",
      "--------------------\n",
      "dec_out: tf.Tensor(\n",
      "[[[ 0.911646    0.67792666 -1.645063    0.05549037]\n",
      "  [ 1.291362    0.59009176 -0.61343676 -1.2680172 ]\n",
      "  [ 1.1346469   0.43835765  0.01451088 -1.5875155 ]\n",
      "  [ 0.8302324   1.1150476  -0.6765634  -1.2687166 ]\n",
      "  [-0.9883821   0.91137624 -1.0078065   1.0848124 ]\n",
      "  [ 1.431666    0.41390756 -1.1176401  -0.72793347]\n",
      "  [-0.3465777   1.2544338   0.51925665 -1.4271128 ]\n",
      "  [ 1.2686902   0.22362366  0.03707819 -1.5293921 ]\n",
      "  [ 1.2686902   0.2236237   0.03707822 -1.5293921 ]\n",
      "  [ 1.2686902   0.2236237   0.03707822 -1.5293921 ]]\n",
      "\n",
      " [[ 1.0469577   0.5542346  -1.6113946   0.01020217]\n",
      "  [-0.551956    1.3676608   0.4559068  -1.2716116 ]\n",
      "  [-0.9093986   1.6900556  -0.31289572 -0.4677612 ]\n",
      "  [ 0.9248402   0.35081324  0.4128761  -1.6885295 ]\n",
      "  [ 1.5343273  -0.30597168  0.01740119 -1.2457567 ]\n",
      "  [ 1.3596575   0.48779914 -1.24531    -0.60214686]\n",
      "  [-0.7579558   1.6761132  -0.771039   -0.14711839]\n",
      "  [-0.13271315  1.6674509  -0.8775543  -0.65718347]\n",
      "  [ 1.5418655   0.22985637 -0.89832383 -0.873398  ]\n",
      "  [-0.5960543   1.1848509   0.72233784 -1.3111346 ]]], shape=(2, 10, 4), dtype=float32)\n",
      "--------------------\n",
      "dec_self_attn_weights.shape: (2, 2, 10, 10)\n",
      "dec_enc_attn_weights: (2, 2, 10, 8)\n"
     ]
    }
   ],
   "source": [
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "dec_layer = DecoderLayer(d_model, num_heads, dff)\n",
    "\n",
    "inp_padding_mask = create_padding_mask(inp)\n",
    "tar_padding_mask = create_padding_mask(tar)\n",
    "\n",
    "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
    "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "dec_out, dec_self_attn_weights, dec_enc_attn_weights = dec_layer(\n",
    "    emb_tar, enc_out, False, combined_mask, inp_padding_mask\n",
    ")\n",
    "\n",
    "print(\"emb_tar:\", emb_tar)\n",
    "print(\"-\" * 20)\n",
    "print(\"enc_out:\", enc_out)\n",
    "print(\"-\" * 20)\n",
    "print(\"dec_out:\", dec_out)\n",
    "assert emb_tar.shape == dec_out.shape\n",
    "print(\"-\" * 20)\n",
    "print(\"dec_self_attn_weights.shape:\", dec_self_attn_weights.shape)\n",
    "print(\"dec_enc_attn_weights:\", dec_enc_attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50, 512), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        ...,\n",
       "        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,\n",
       "          0.99998724,  0.99998814],\n",
       "        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,\n",
       "          0.9999867 ,  0.9999876 ],\n",
       "        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,\n",
       "          0.9999861 ,  0.9999871 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis, :],\n",
    "                           d_model)\n",
    "    \n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = np.concatenate([sines, cosines], axis=1)\n",
    "    \n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "seq_len = 50\n",
    "d_model = 512\n",
    "\n",
    "pos_encoding = positional_encoding(seq_len, d_model)\n",
    "pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('d_model')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    # Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：\n",
    "    # - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`\n",
    "    # - input_vocab_size: 用來把索引轉成詞嵌入向量\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "                 rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "    \n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
    "    \n",
    "        # 建立 `num_layers` 個 EncoderLayers\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        # 輸入的 x.shape == (batch_size, input_seq_len)\n",
    "        # 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)\n",
    "        input_seq_len = tf.shape(x)[1]\n",
    "    \n",
    "        # 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)\n",
    "        # 再加上對應長度的位置編碼\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :input_seq_len, :]\n",
    "\n",
    "        # 對 embedding 跟位置編碼的總合做 regularization\n",
    "        # 這在 Decoder 也會做\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        # 通過 N 個 EncoderLayer 做編碼\n",
    "        for i, enc_layer in enumerate(self.enc_layers):\n",
    "            x = enc_layer(x, training, mask)\n",
    "            # 以下只是用來 demo EncoderLayer outputs\n",
    "            #print('-' * 20)\n",
    "            #print(f\"EncoderLayer {i + 1}'s output:\", x)\n",
    "      \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: tf.Tensor(\n",
      "[[8113  103    9 1066 7903 8114    0    0]\n",
      " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
      "--------------------\n",
      "enc_out: tf.Tensor(\n",
      "[[[-1.0038205  -0.45496085 -0.19832987  1.6571113 ]\n",
      "  [-0.55373764 -0.61151147 -0.5664016   1.7316508 ]\n",
      "  [-0.5271825  -0.3902845  -0.79603344  1.7135004 ]\n",
      "  [-0.7932742  -0.18683454 -0.7048304   1.6849391 ]\n",
      "  [-1.0119269  -0.08384517 -0.5403726   1.6361448 ]\n",
      "  [-1.1781926  -0.10394833 -0.3020925   1.5842334 ]\n",
      "  [-1.069806   -0.34945896 -0.2194089   1.6386738 ]\n",
      "  [-0.66219264 -0.60785806 -0.45710376  1.7271545 ]]\n",
      "\n",
      " [[-1.013355   -0.43549132 -0.2066725   1.6555188 ]\n",
      "  [-0.6518722  -0.5328544  -0.5454718   1.7301984 ]\n",
      "  [-0.5431334  -0.39416707 -0.7784202   1.7157208 ]\n",
      "  [-0.75860286 -0.19505598 -0.7339016   1.6875606 ]\n",
      "  [-1.0094789  -0.09481923 -0.53464025  1.6389384 ]\n",
      "  [-1.1836779  -0.11553008 -0.2835592   1.5827671 ]\n",
      "  [-1.1175152  -0.27072194 -0.23169592  1.6199334 ]\n",
      "  [-0.7388084  -0.55241764 -0.4303427   1.7215688 ]]], shape=(2, 8, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 超參數\n",
    "num_layers = 2 # 2 層的 Encoder\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "input_vocab_size = subword_encoder_en.vocab_size + 2 # 記得加上 <start>, <end>\n",
    "\n",
    "# 初始化一個 Encoder\n",
    "encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
    "\n",
    "# 將 2 維的索引序列丟入 Encoder 做編碼\n",
    "enc_out = encoder(inp, training=False, mask=None)\n",
    "print(\"inp:\", inp)\n",
    "print(\"-\" * 20)\n",
    "print(\"enc_out:\", enc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, combined_mask, inp_padding_mask):\n",
    "        tar_seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        attention_weights = {}  # 用來存放每個 Decoder layer 的注意權重\n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :tar_seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i, dec_layer in enumerate(self.dec_layers):\n",
    "            x, block1, block2 = dec_layer(x, enc_output, training, combined_mask, inp_padding_mask)\n",
    "                \n",
    "            attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
    "            \n",
    "        # x.shape == (batch_size, tar_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: tf.Tensor(\n",
      "[[4205   10  241   86   27    3 4206    0    0    0]\n",
      " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
      "--------------------\n",
      "combined_mask: tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n",
      "--------------------\n",
      "enc_out: tf.Tensor(\n",
      "[[[-1.0038205  -0.45496085 -0.19832987  1.6571113 ]\n",
      "  [-0.55373764 -0.61151147 -0.5664016   1.7316508 ]\n",
      "  [-0.5271825  -0.3902845  -0.79603344  1.7135004 ]\n",
      "  [-0.7932742  -0.18683454 -0.7048304   1.6849391 ]\n",
      "  [-1.0119269  -0.08384517 -0.5403726   1.6361448 ]\n",
      "  [-1.1781926  -0.10394833 -0.3020925   1.5842334 ]\n",
      "  [-1.069806   -0.34945896 -0.2194089   1.6386738 ]\n",
      "  [-0.66219264 -0.60785806 -0.45710376  1.7271545 ]]\n",
      "\n",
      " [[-1.013355   -0.43549132 -0.2066725   1.6555188 ]\n",
      "  [-0.6518722  -0.5328544  -0.5454718   1.7301984 ]\n",
      "  [-0.5431334  -0.39416707 -0.7784202   1.7157208 ]\n",
      "  [-0.75860286 -0.19505598 -0.7339016   1.6875606 ]\n",
      "  [-1.0094789  -0.09481923 -0.53464025  1.6389384 ]\n",
      "  [-1.1836779  -0.11553008 -0.2835592   1.5827671 ]\n",
      "  [-1.1175152  -0.27072194 -0.23169592  1.6199334 ]\n",
      "  [-0.7388084  -0.55241764 -0.4303427   1.7215688 ]]], shape=(2, 8, 4), dtype=float32)\n",
      "--------------------\n",
      "inp_padding_mask: tf.Tensor(\n",
      "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
      "--------------------\n",
      "dec_out: tf.Tensor(\n",
      "[[[-1.1557608  -0.76461244  1.3034496   0.61692387]\n",
      "  [ 0.48080432 -1.519914    1.1973474  -0.15823767]\n",
      "  [ 0.9180802  -1.3970723   0.97793615 -0.49894407]\n",
      "  [ 0.9766772  -1.6286404   0.6268924   0.0250708 ]\n",
      "  [-0.01132949 -1.6288849   0.7932094   0.84700507]\n",
      "  [-0.25414705 -1.4014618   1.3758855   0.2797234 ]\n",
      "  [ 0.13929638 -1.4435863   1.3753532  -0.07106314]\n",
      "  [ 0.570994   -1.3613054   1.2636327  -0.47332126]\n",
      "  [ 0.8748356  -1.3937079   1.0202296  -0.50135744]\n",
      "  [ 0.9943848  -1.6450421   0.54137     0.10928728]]\n",
      "\n",
      " [[-1.157126   -0.7574236   1.3140727   0.60047686]\n",
      "  [ 0.54361695 -1.4501399   1.2248418  -0.31831893]\n",
      "  [ 0.8961092  -1.4328651   0.9754209  -0.43866503]\n",
      "  [ 0.94813526 -1.643827    0.6279085   0.06778312]\n",
      "  [ 0.14019877 -1.6649879   0.9134931   0.611296  ]\n",
      "  [-0.25183892 -1.385474    1.4003067   0.23700616]\n",
      "  [ 0.0990947  -1.4293538   1.3939383  -0.06367907]\n",
      "  [ 0.48295584 -1.3606007   1.3135729  -0.4359281 ]\n",
      "  [ 0.8215776  -1.3997822   1.0631976  -0.4849931 ]\n",
      "  [ 1.0307528  -1.5789545   0.6576233  -0.1094217 ]]], shape=(2, 10, 4), dtype=float32)\n",
      "--------------------\n",
      "decoder_layer1_block1.shape: (2, 2, 10, 10)\n",
      "decoder_layer1_block2.shape: (2, 2, 10, 8)\n",
      "decoder_layer2_block1.shape: (2, 2, 10, 10)\n",
      "decoder_layer2_block2.shape: (2, 2, 10, 8)\n"
     ]
    }
   ],
   "source": [
    "# 超參數\n",
    "num_layers = 2 # 2 層的 Decoder\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "target_vocab_size = subword_encoder_zh.vocab_size + 2 # 記得加上 <start>, <end>\n",
    "\n",
    "# 遮罩\n",
    "inp_padding_mask = create_padding_mask(inp)\n",
    "tar_padding_mask = create_padding_mask(tar)\n",
    "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
    "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "# 初始化一個 Decoder\n",
    "decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
    "\n",
    "# 將 2 維的索引序列以及遮罩丟入 Decoder\n",
    "print(\"tar:\", tar)\n",
    "print(\"-\" * 20)\n",
    "print(\"combined_mask:\", combined_mask)\n",
    "print(\"-\" * 20)\n",
    "print(\"enc_out:\", enc_out)\n",
    "print(\"-\" * 20)\n",
    "print(\"inp_padding_mask:\", inp_padding_mask)\n",
    "print(\"-\" * 20)\n",
    "dec_out, attn = decoder(tar, enc_out, training=False, \n",
    "                        combined_mask=combined_mask,\n",
    "                        inp_padding_mask=inp_padding_mask)\n",
    "print(\"dec_out:\", dec_out)\n",
    "print(\"-\" * 20)\n",
    "for block_name, attn_weights in attn.items():\n",
    "    print(f\"{block_name}.shape: {attn_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_szie, target_vocab_szie, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, rate)\n",
    "        \n",
    "        # 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    # enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，\n",
    "    # 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用\n",
    "    def call(self, inp, tar, training, enc_padding_mask, combined_mask, dec_padding_mask):\n",
    "        # (batch_size, inp_seq_len, d_model)\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "        \n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, combined_mask, dec_padding_mask)\n",
    "        \n",
    "        # (batch_size, tar_seq_len, target_vocab_size)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        \n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: tf.Tensor(\n",
      "[[4205   10  241   86   27    3 4206    0    0    0]\n",
      " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
      "--------------------\n",
      "tar_inp: tf.Tensor(\n",
      "[[4205   10  241   86   27    3 4206    0    0]\n",
      " [4205  165  489  398  191   14    7  560    3]], shape=(2, 9), dtype=int64)\n",
      "--------------------\n",
      "tar_real: tf.Tensor(\n",
      "[[  10  241   86   27    3 4206    0    0    0]\n",
      " [ 165  489  398  191   14    7  560    3 4206]], shape=(2, 9), dtype=int64)\n",
      "--------------------\n",
      "predictions: tf.Tensor(\n",
      "[[[ 0.09636697 -0.06143762  0.04594332 ...  0.00860998  0.00873263\n",
      "   -0.0554506 ]\n",
      "  [ 0.09114663 -0.06999018  0.05286894 ...  0.00027743 -0.00401425\n",
      "   -0.05197208]\n",
      "  [ 0.09321959 -0.06701639  0.05042911 ...  0.00369672  0.00133362\n",
      "   -0.05361196]\n",
      "  ...\n",
      "  [ 0.09338701 -0.06670718  0.05015506 ...  0.00437496  0.00249683\n",
      "   -0.05399878]\n",
      "  [ 0.08867302 -0.07300584  0.05531472 ... -0.0027572  -0.00856237\n",
      "   -0.05052562]\n",
      "  [ 0.09297653 -0.06736148  0.05068985 ...  0.00365756  0.00137583\n",
      "   -0.05367357]]\n",
      "\n",
      " [[ 0.09562723 -0.0629437   0.04716522 ...  0.00711586  0.0064028\n",
      "   -0.05486218]\n",
      "  [ 0.08480859 -0.07689578  0.0585032  ... -0.00724741 -0.01536205\n",
      "   -0.04809175]\n",
      "  [ 0.09106088 -0.07010493  0.05291519 ...  0.00091081 -0.00280215\n",
      "   -0.05244778]\n",
      "  ...\n",
      "  [ 0.09082542 -0.07040977  0.05314614 ...  0.00086519 -0.00278118\n",
      "   -0.05248944]\n",
      "  [ 0.08701327 -0.07485107  0.05678491 ... -0.00420109 -0.0105516\n",
      "   -0.04989709]\n",
      "  [ 0.09055014 -0.07077272  0.05344864 ...  0.0003711  -0.00357164\n",
      "   -0.05222975]]], shape=(2, 9, 4207), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 超參數\n",
    "num_layers = 6\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "\n",
    "# + 2 是為了 <start> & <end> token\n",
    "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
    "output_vocab_size = subword_encoder_zh.vocab_size + 2\n",
    "\n",
    "# 重點中的重點。訓練時用前一個字來預測下一個中文字\n",
    "tar_inp = tar[:, :-1]\n",
    "tar_real = tar[:, 1:]\n",
    "\n",
    "# 來源 / 目標語言用的遮罩。注意 `combined_mask` 已經將目標語言的兩種遮罩合而為一\n",
    "inp_padding_mask = create_padding_mask(inp)\n",
    "tar_padding_mask = create_padding_mask(tar_inp)\n",
    "look_ahead_mask = create_look_ahead_mask(tar_inp.shape[1])\n",
    "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "# 初始化我們的第一個 transformer\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff, \n",
    "                          input_vocab_size, output_vocab_size)\n",
    "\n",
    "# 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果\n",
    "predictions, attn_weights = transformer(inp, tar_inp, False, inp_padding_mask, \n",
    "                                        combined_mask, inp_padding_mask)\n",
    "\n",
    "print(\"tar:\", tar)\n",
    "print(\"-\" * 20)\n",
    "print(\"tar_inp:\", tar_inp)\n",
    "print(\"-\" * 20)\n",
    "print(\"tar_real:\", tar_real)\n",
    "print(\"-\" * 20)\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_4 (Encoder)          multiple                  33492     \n",
      "_________________________________________________________________\n",
      "decoder_7 (Decoder)          multiple                  18388     \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            multiple                  21035     \n",
      "=================================================================\n",
      "Total params: 72,915\n",
      "Trainable params: 72,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0 \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    \n",
    "    # 照樣計算所有位置的 cross entropy 但不加總\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    # 只計算非 <pad> 位置的損失 \n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_vocab_size: 8115\n",
      "target_vocab_size: 4207\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4 \n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
    "target_vocab_size = subword_encoder_zh.vocab_size + 2\n",
    "dropout_rate = 0.1  # 預設值\n",
    "\n",
    "print(\"input_vocab_size:\", input_vocab_size)\n",
    "print(\"target_vocab_size:\", target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        \n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "\n",
    "# 將客製化 learning rate schdeule 丟入 Adam opt.\n",
    "# Adam opt. 的參數都跟論文相同\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_models = [128, 256, 512]\n",
    "warmup_steps = [1000 * i for i in range(1, 4)]\n",
    "\n",
    "schedules = []\n",
    "labels = []\n",
    "colors = [\"blue\", \"red\", \"black\"]\n",
    "for d in d_models:\n",
    "    schedules += [CustomSchedule(d, s) for s in warmup_steps]\n",
    "    labels += [f\"d_model: {d}, warm: {s}\" for s in warmup_steps]\n",
    "\n",
    "for i, (schedule, label) in enumerate(zip(schedules, labels)):\n",
    "    plt.plot(schedule(tf.range(10000, dtype=tf.float32)), \n",
    "           label=label, color=colors[i // 3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這個 Transformer 有 4 層 Encoder / Decoder layers\n",
      "d_model: 128\n",
      "num_heads: 8\n",
      "dff: 512\n",
      "input_vocab_size: 8115\n",
      "target_vocab_size: 4207\n",
      "dropout_rate: 0.1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, dropout_rate)\n",
    "\n",
    "print(f\"\"\"這個 Transformer 有 {num_layers} 層 Encoder / Decoder layers\n",
    "d_model: {d_model}\n",
    "num_heads: {num_heads}\n",
    "dff: {dff}\n",
    "input_vocab_size: {input_vocab_size}\n",
    "target_vocab_size: {target_vocab_size}\n",
    "dropout_rate: {dropout_rate}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒找到 checkpoint，從頭訓練。\n"
     ]
    }
   ],
   "source": [
    "train_perc = 20\n",
    "val_prec = 1\n",
    "drop_prec = 100 - train_perc - val_prec\n",
    "\n",
    "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
    "log_dir = os.path.join(output_dir, 'logs')\n",
    "download_dir = \"tensorflow-datasets/downloads\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "run_id = f\"{num_layers}layers_{d_model}d_{num_heads}heads_{dff}dff_{train_perc}train_perc\"\n",
    "checkpoint_path = os.path.join(checkpoint_path, run_id)\n",
    "log_dir = os.path.join(log_dir, run_id)\n",
    "\n",
    "# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取\n",
    "# 一般來說你會想存下模型以及 optimizer 的狀態\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西\n",
    "# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果在 checkpoint 路徑上有發現檔案就讀進來\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  \n",
    "    # 用來確認之前訓練多少 epochs 了\n",
    "    last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "    print(f'已讀取最新的 checkpoint，模型已訓練 {last_epoch} epochs。')\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    print(\"沒找到 checkpoint，從頭訓練。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # 讓 TensorFlow 幫我們將 eager code 優化並加快運算\n",
    "def train_step(inp, tar):\n",
    "    # 前面說過的，用去尾的原始序列去預測下一個字的序列\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    # 建立 3 個遮罩\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    # 紀錄 Transformer 的所有運算過程以方便之後做梯度下降\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        # 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    # 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    # 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此超參數組合的 Transformer 已經訓練 0 epochs。\n",
      "剩餘 epochs：-30\n"
     ]
    }
   ],
   "source": [
    "# 定義我們要看幾遍數據集\n",
    "EPOCHS = 30\n",
    "print(f\"此超參數組合的 Transformer 已經訓練 {last_epoch} epochs。\")\n",
    "print(f\"剩餘 epochs：{min(0, last_epoch - EPOCHS)}\")\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "for epoch in range(last_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "            \n",
    "    with summary_writer.as_default():\n",
    "        tf.summart.scalar('train_loss', train_loss.result(), step=epoch + 1)\n",
    "        tf.summart.scalar('train_acc', train_accuracy.result(), step=epoch + 1)\n",
    "        \n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "    print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict\n",
    "def evaluate(inp_sentence):\n",
    "    # 準備英文句子前後會加上的 <start>, <end>\n",
    "    start_token = [subword_encoder_en.vocab_size]\n",
    "    end_token = [subword_encoder_en.vocab_size + 1]\n",
    "\n",
    "    # inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列\n",
    "    # 並在前後加上 BOS / EOS\n",
    "    inp_sentence = start_token + subword_encoder_en.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入\n",
    "    # 是一個只包含一個中文 <start> token 的序列\n",
    "    decoder_input = [subword_encoder_zh.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)  # 增加 batch 維度\n",
    "\n",
    "    # auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 每多一個生成的字就得產生新的遮罩\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字\n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 遇到 <end> token 就停止回傳，代表模型已經產生完結果\n",
    "        if tf.equal(predicted_id, subword_encoder_zh.vocab_size + 1):\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # 將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生\n",
    "        # 下個中文字的時候關注到最新的 `predicted_id`\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    # 將 batch 的維度去掉後回傳預測的中文索引序列\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (network-practice)",
   "language": "python",
   "name": "pycharm-bfff986b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
